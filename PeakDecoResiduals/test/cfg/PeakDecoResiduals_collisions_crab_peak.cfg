[CRAB]

jobtype = cmssw
scheduler = glite
#scheduler = caf
### NOTE: just setting the name of the server (pi, lnl etc etc )
###       crab will submit the jobs to the server...
#server_name = caf
use_server = 1

[CMSSW]

### The data you want to access (to be found on DBS)
#datasetpath=/MinimumBias/BeamCommissioning09-BSCNOBEAMHALO-Jan29Skim-v2/RAW-RECO
#datasetpath=/MinimumBias/BeamCommissioning09-BSCNOBEAMHALO-Jan23Skim-v1/RAW-RECO 
#datasetpath=/MinimumBias/BeamCommissioning09-BSCNOBEAMHALO-Dec19thSkim_341_v2/RAW-RECO
datasetpath=/MinimumBias/Commissioning10-GOODCOLL-v7/RAW-RECO 

#dbs_url=http://cmsdbsprod.cern.ch/cms_dbs_caf_analysis_01/servlet/DBSServlet


### The ParameterSet you want to use
pset=cfg/PeakDecoResiduals_collisions_cfg.py

### Splitting parameters
total_number_of_events=1000
#total_number_of_events=100000
#events_per_job = 10000
number_of_jobs = 10

### The output files (comma separated list)
output_file = temp.root

[USER]

### CRAFT09 3.8T peak alignment
#additional_input_files = TrackerAlignment_2009_v1_prompt_NEW.db
### Feb2010 cosmics 3.8 T alignment
additional_input_files = TrackerAlignment_Feb2010Cosmics_38T.db

###stage out to castor
#return_data = 0
#copy_data = 1
#storage_element=T2_CH_CAF
#user_remote_dir=PeakDecoResiduals/trial
#ui_working_dir=trial/peak

###write to tempdir
return_data = 1
#ui_working_dir=peak

[GRID]
##UCSD 
SE_white_list = T2_US_UCSD
##WISC
#SE_white_list = T2_US_Wisconsin
##DESY
#SE_white_list = T2_DE_DESY
##Purdue
#SE_white_list = T2_US_Purdue
##MIT
#SE_white_list = T2_US_MIT
##Nebraska
#SE_white_list = T2_US_Nebraska
##IFCA
#SE_white_list = T2_ES_IFCA
##Lyon
#SE_white_list = T2_FR_CCIN2P3
##CIEMAT
#SE_white_list = T2_ES_CIEMAT
##IIHE
#SE_white_list = T2_BE_IIHE
##Aachen
#SE_white_list = T2_DE_RWTH