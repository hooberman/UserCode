[CRAB]

jobtype = cmssw
#scheduler = glite
scheduler = caf
### NOTE: just setting the name of the server (pi, lnl etc etc )
###       crab will submit the jobs to the server...
#server_name = caf

[CMSSW]

### The data you want to access (to be found on DBS)
#datasetpath=/MinimumBias/BeamCommissioning09-BSCNOBEAMHALO-Jan29Skim-v2/RAW-RECO
#datasetpath=/MinimumBias/BeamCommissioning09-BSCNOBEAMHALO-Jan23Skim-v1/RAW-RECO 
datasetpath=/MinimumBias/BeamCommissioning09-BSCNOBEAMHALO-Dec19thSkim_341_v2/RAW-RECO

dbs_url=http://cmsdbsprod.cern.ch/cms_dbs_caf_analysis_01/servlet/DBSServlet

###PEAK
#runselection=123596
###DECO
#runselection=124275

runselection=124230, 124230, 124120, 124030, 124027, 124025, 124024, 124023, 124022, 124020, 124009, 124008, 124006, 123908, 123906, 123818, 123815, 123732, 123615, 123596, 123592

### The ParameterSet you want to use
pset=cfg/PeakDecoResiduals_collisions_cfg.py

### Splitting parameters
total_number_of_events=-1
#total_number_of_events=100000
#events_per_job = 10000
number_of_jobs = 10

### The output files (comma separated list)
output_file = temp.root

[USER]

additional_input_files = TrackerAlignment_2009_v1_prompt.db


###stage out to castor
#return_data = 0
#copy_data = 1
#storage_element=T2_CH_CAF
#user_remote_dir=PeakDecoResiduals/trial
#ui_working_dir=trial/peak

###write to tempdir
return_data = 1
#ui_working_dir=peak


